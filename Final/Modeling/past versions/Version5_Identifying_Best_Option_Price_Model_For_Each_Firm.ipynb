{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c8837d",
   "metadata": {},
   "source": [
    "<h2>Identifying the Best Option Price Model for each Firm<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5248605",
   "metadata": {},
   "source": [
    "The goal of the project is to determine for each firm, which model would best approximate the option price. \n",
    "\n",
    "Here is the structure of the code:\n",
    "\n",
    "We look at the firms from $faangTickers$.\n",
    "\n",
    "We also pre-determined a list of features that is of our interest\n",
    "\n",
    "We go through each of firm in $faangTickers$. Before computing the MSE, we use TimeSeriesSplit to split the data chronically according to the dates towards expiration (it only makes sense to use the data of the options that expire recently to predict behavior of the options expires in the future).\n",
    "\n",
    "Now we loop through each power set of features. After splitting, we train the data using the models from the models_list, and compute their respective mse for each split, and records them in rmses. $rmses$ is a 2-d table, rows corresponds to different models, columns corresponds to the splits for each subset of features (1-5).\n",
    "\n",
    "Then by taking the average across all splits for each feature, we produce $amses$, whose rows corresponds to different models, and columns corresponds to the average mse of each feature.\n",
    "\n",
    "And finally, by referring to $amses$, we check which set of features and models performs the best for each firm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b5208",
   "metadata": {},
   "source": [
    "We first import all the packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a56d2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eefaf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For readability, we disallow certain features\n",
    "## block the error messaging\n",
    "logging.getLogger(\"yfinance\").setLevel(logging.CRITICAL)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "133fd2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching options for Meta (Facebook) (META)...\n",
      "  - [1/18] 2025-06-27 OK\n",
      "  - [2/18] 2025-07-03 OK\n",
      "  - [3/18] 2025-07-11 OK\n",
      "  - [4/18] 2025-07-18 OK\n",
      "  - [5/18] 2025-07-25 OK\n",
      "  - [6/18] 2025-08-01 OK\n",
      "  - [7/18] 2025-08-15 OK\n",
      "  - [8/18] 2025-09-19 OK\n",
      "  - [9/18] 2025-10-17 OK\n",
      "  - [10/18] 2025-11-21 OK\n",
      "  - [11/18] 2025-12-19 OK\n",
      "  - [12/18] 2026-01-16 OK\n",
      "  - [13/18] 2026-03-20 OK\n",
      "  - [14/18] 2026-06-18 OK\n",
      "  - [15/18] 2026-09-18 OK\n",
      "  - [16/18] 2026-12-18 OK\n",
      "  - [17/18] 2027-01-15 OK\n",
      "  - [18/18] 2027-12-17 OK\n",
      "Fetching options for Apple (AAPL)...\n",
      "  - [1/20] 2025-06-27 OK\n",
      "  - [2/20] 2025-07-03 OK\n",
      "  - [3/20] 2025-07-11 OK\n",
      "  - [4/20] 2025-07-18 OK\n",
      "  - [5/20] 2025-07-25 OK\n",
      "  - [6/20] 2025-08-01 OK\n",
      "  - [7/20] 2025-08-15 OK\n",
      "  - [8/20] 2025-09-19 OK\n",
      "  - [9/20] 2025-10-17 OK\n",
      "  - [10/20] 2025-11-21 OK\n",
      "  - [11/20] 2025-12-19 OK\n",
      "  - [12/20] 2026-01-16 OK\n",
      "  - [13/20] 2026-02-20 OK\n",
      "  - [14/20] 2026-03-20 OK\n",
      "  - [15/20] 2026-06-18 OK\n",
      "  - [16/20] 2026-09-18 OK\n",
      "  - [17/20] 2026-12-18 OK\n",
      "  - [18/20] 2027-01-15 OK\n",
      "  - [19/20] 2027-06-17 OK\n",
      "  - [20/20] 2027-12-17 OK\n",
      "Fetching options for Amazon (AMZN)...\n",
      "  - [1/19] 2025-06-27 OK\n",
      "  - [2/19] 2025-07-03 OK\n",
      "  - [3/19] 2025-07-11 OK\n",
      "  - [4/19] 2025-07-18 OK\n",
      "  - [5/19] 2025-07-25 OK\n",
      "  - [6/19] 2025-08-01 OK\n",
      "  - [7/19] 2025-08-15 OK\n",
      "  - [8/19] 2025-09-19 OK\n",
      "  - [9/19] 2025-10-17 OK\n",
      "  - [10/19] 2025-11-21 OK\n",
      "  - [11/19] 2025-12-19 OK\n",
      "  - [12/19] 2026-01-16 OK\n",
      "  - [13/19] 2026-03-20 OK\n",
      "  - [14/19] 2026-06-18 OK\n",
      "  - [15/19] 2026-09-18 OK\n",
      "  - [16/19] 2026-12-18 OK\n",
      "  - [17/19] 2027-01-15 OK\n",
      "  - [18/19] 2027-06-17 OK\n",
      "  - [19/19] 2027-12-17 OK\n",
      "Fetching options for Netflix (NFLX)...\n",
      "  - [1/18] 2025-06-27 OK\n",
      "  - [2/18] 2025-07-03 OK\n",
      "  - [3/18] 2025-07-11 OK\n",
      "  - [4/18] 2025-07-18 OK\n",
      "  - [5/18] 2025-07-25 OK\n",
      "  - [6/18] 2025-08-01 OK\n",
      "  - [7/18] 2025-08-15 OK\n",
      "  - [8/18] 2025-09-19 OK\n",
      "  - [9/18] 2025-10-17 OK\n",
      "  - [10/18] 2025-12-19 OK\n",
      "  - [11/18] 2026-01-16 OK\n",
      "  - [12/18] 2026-03-20 OK\n",
      "  - [13/18] 2026-06-18 OK\n",
      "  - [14/18] 2026-09-18 OK\n",
      "  - [15/18] 2026-12-18 OK\n",
      "  - [16/18] 2027-01-15 OK\n",
      "  - [17/18] 2027-06-17 OK\n",
      "  - [18/18] 2027-12-17 OK\n",
      "Fetching options for Google (GOOGL)...\n",
      "  - [1/19] 2025-06-27 OK\n",
      "  - [2/19] 2025-07-03 OK\n",
      "  - [3/19] 2025-07-11 OK\n",
      "  - [4/19] 2025-07-18 OK\n",
      "  - [5/19] 2025-07-25 OK\n",
      "  - [6/19] 2025-08-01 OK\n",
      "  - [7/19] 2025-08-15 OK\n",
      "  - [8/19] 2025-09-19 OK\n",
      "  - [9/19] 2025-10-17 OK\n",
      "  - [10/19] 2025-11-21 OK\n",
      "  - [11/19] 2025-12-19 OK\n",
      "  - [12/19] 2026-01-16 OK\n",
      "  - [13/19] 2026-03-20 OK\n",
      "  - [14/19] 2026-06-18 OK\n",
      "  - [15/19] 2026-09-18 OK\n",
      "  - [16/19] 2026-12-18 OK\n",
      "  - [17/19] 2027-01-15 OK\n",
      "  - [18/19] 2027-06-17 OK\n",
      "  - [19/19] 2027-12-17 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractSymbol</th>\n",
       "      <th>lastTradeDate</th>\n",
       "      <th>strike</th>\n",
       "      <th>lastPrice</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>change</th>\n",
       "      <th>percentChange</th>\n",
       "      <th>volume</th>\n",
       "      <th>openInterest</th>\n",
       "      <th>...</th>\n",
       "      <th>option_type</th>\n",
       "      <th>ticker</th>\n",
       "      <th>midPrice</th>\n",
       "      <th>ask_bid_spread</th>\n",
       "      <th>days_to_exp</th>\n",
       "      <th>T</th>\n",
       "      <th>spot</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>log_moneyness</th>\n",
       "      <th>bs_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14090</th>\n",
       "      <td>GOOGL271217P00140000</td>\n",
       "      <td>2025-06-23 19:57:26+00:00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>16.59</td>\n",
       "      <td>16.35</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>3.622735</td>\n",
       "      <td>13.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>...</td>\n",
       "      <td>put</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>16.575</td>\n",
       "      <td>0.45</td>\n",
       "      <td>906</td>\n",
       "      <td>2.482192</td>\n",
       "      <td>165.190002</td>\n",
       "      <td>1.179929</td>\n",
       "      <td>0.165454</td>\n",
       "      <td>11.046335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>AAPL250919C00210000</td>\n",
       "      <td>2025-06-23 19:54:18+00:00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.90</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-2.469139</td>\n",
       "      <td>845.0</td>\n",
       "      <td>12610.0</td>\n",
       "      <td>...</td>\n",
       "      <td>call</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>7.850</td>\n",
       "      <td>0.10</td>\n",
       "      <td>87</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>0.959524</td>\n",
       "      <td>-0.041318</td>\n",
       "      <td>8.573163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>META251017P00860000</td>\n",
       "      <td>2025-06-20 13:45:36+00:00</td>\n",
       "      <td>860.0</td>\n",
       "      <td>166.70</td>\n",
       "      <td>161.75</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>put</td>\n",
       "      <td>META</td>\n",
       "      <td>163.375</td>\n",
       "      <td>3.25</td>\n",
       "      <td>115</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>698.530029</td>\n",
       "      <td>0.812244</td>\n",
       "      <td>-0.207954</td>\n",
       "      <td>154.032561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>AAPL260618C00170000</td>\n",
       "      <td>2025-06-23 19:17:54+00:00</td>\n",
       "      <td>170.0</td>\n",
       "      <td>46.21</td>\n",
       "      <td>46.50</td>\n",
       "      <td>46.75</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.895196</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>...</td>\n",
       "      <td>call</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>46.625</td>\n",
       "      <td>0.25</td>\n",
       "      <td>359</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>1.185294</td>\n",
       "      <td>0.169991</td>\n",
       "      <td>51.068982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9218</th>\n",
       "      <td>NFLX250801C01220000</td>\n",
       "      <td>2025-06-23 15:28:25+00:00</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>82.75</td>\n",
       "      <td>86.05</td>\n",
       "      <td>89.90</td>\n",
       "      <td>4.300003</td>\n",
       "      <td>5.481202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>call</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>87.975</td>\n",
       "      <td>3.85</td>\n",
       "      <td>38</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>1253.540039</td>\n",
       "      <td>1.027492</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>91.147358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7107</th>\n",
       "      <td>AMZN251121P00245000</td>\n",
       "      <td>2025-06-16 18:55:12+00:00</td>\n",
       "      <td>245.0</td>\n",
       "      <td>33.85</td>\n",
       "      <td>38.75</td>\n",
       "      <td>39.15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>put</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>38.950</td>\n",
       "      <td>0.40</td>\n",
       "      <td>150</td>\n",
       "      <td>0.410959</td>\n",
       "      <td>208.470001</td>\n",
       "      <td>0.850898</td>\n",
       "      <td>-0.161463</td>\n",
       "      <td>35.396377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>AAPL250815P00175000</td>\n",
       "      <td>2025-06-23 19:52:56+00:00</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-15.789472</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6086.0</td>\n",
       "      <td>...</td>\n",
       "      <td>put</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.605</td>\n",
       "      <td>0.03</td>\n",
       "      <td>52</td>\n",
       "      <td>0.142466</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>1.151429</td>\n",
       "      <td>0.141003</td>\n",
       "      <td>1.376708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>GOOGL250718C00200000</td>\n",
       "      <td>2025-06-23 19:59:31+00:00</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>-26.315786</td>\n",
       "      <td>2683.0</td>\n",
       "      <td>16611.0</td>\n",
       "      <td>...</td>\n",
       "      <td>call</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.01</td>\n",
       "      <td>24</td>\n",
       "      <td>0.065753</td>\n",
       "      <td>165.190002</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>-0.191221</td>\n",
       "      <td>0.117213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6720</th>\n",
       "      <td>AMZN250801P00220000</td>\n",
       "      <td>2025-06-23 19:12:06+00:00</td>\n",
       "      <td>220.0</td>\n",
       "      <td>14.74</td>\n",
       "      <td>14.90</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1.655171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>put</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>15.200</td>\n",
       "      <td>0.60</td>\n",
       "      <td>38</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>208.470001</td>\n",
       "      <td>0.947591</td>\n",
       "      <td>-0.053832</td>\n",
       "      <td>14.605194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12147</th>\n",
       "      <td>NFLX270617C01340000</td>\n",
       "      <td>2025-06-04 19:54:43+00:00</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>260.85</td>\n",
       "      <td>261.10</td>\n",
       "      <td>269.45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>call</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>265.275</td>\n",
       "      <td>8.35</td>\n",
       "      <td>723</td>\n",
       "      <td>1.980822</td>\n",
       "      <td>1253.540039</td>\n",
       "      <td>0.935478</td>\n",
       "      <td>-0.066698</td>\n",
       "      <td>309.176726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             contractSymbol             lastTradeDate  strike  lastPrice  \\\n",
       "14090  GOOGL271217P00140000 2025-06-23 19:57:26+00:00   140.0      16.59   \n",
       "4852    AAPL250919C00210000 2025-06-23 19:54:18+00:00   210.0       7.90   \n",
       "2016    META251017P00860000 2025-06-20 13:45:36+00:00   860.0     166.70   \n",
       "5591    AAPL260618C00170000 2025-06-23 19:17:54+00:00   170.0      46.21   \n",
       "9218    NFLX250801C01220000 2025-06-23 15:28:25+00:00  1220.0      82.75   \n",
       "7107    AMZN251121P00245000 2025-06-16 18:55:12+00:00   245.0      33.85   \n",
       "4781    AAPL250815P00175000 2025-06-23 19:52:56+00:00   175.0       1.60   \n",
       "12669  GOOGL250718C00200000 2025-06-23 19:59:31+00:00   200.0       0.14   \n",
       "6720    AMZN250801P00220000 2025-06-23 19:12:06+00:00   220.0      14.74   \n",
       "12147   NFLX270617C01340000 2025-06-04 19:54:43+00:00  1340.0     260.85   \n",
       "\n",
       "          bid     ask    change  percentChange  volume  openInterest  ...  \\\n",
       "14090   16.35   16.80  0.580000       3.622735    13.0         474.0  ...   \n",
       "4852     7.80    7.90 -0.200000      -2.469139   845.0       12610.0  ...   \n",
       "2016   161.75  165.00  0.000000       0.000000     5.0           4.0  ...   \n",
       "5591    46.50   46.75  0.410000       0.895196    28.0        2046.0  ...   \n",
       "9218    86.05   89.90  4.300003       5.481202     3.0          28.0  ...   \n",
       "7107    38.75   39.15  0.000000       0.000000     2.0          31.0  ...   \n",
       "4781     1.59    1.62 -0.300000     -15.789472   759.0        6086.0  ...   \n",
       "12669    0.13    0.14 -0.050000     -26.315786  2683.0       16611.0  ...   \n",
       "6720    14.90   15.50  0.240000       1.655171     1.0          44.0  ...   \n",
       "12147  261.10  269.45  0.000000       0.000000     3.0          47.0  ...   \n",
       "\n",
       "       option_type  ticker midPrice ask_bid_spread days_to_exp         T  \\\n",
       "14090          put   GOOGL   16.575           0.45         906  2.482192   \n",
       "4852          call    AAPL    7.850           0.10          87  0.238356   \n",
       "2016           put    META  163.375           3.25         115  0.315068   \n",
       "5591          call    AAPL   46.625           0.25         359  0.983562   \n",
       "9218          call    NFLX   87.975           3.85          38  0.104110   \n",
       "7107           put    AMZN   38.950           0.40         150  0.410959   \n",
       "4781           put    AAPL    1.605           0.03          52  0.142466   \n",
       "12669         call   GOOGL    0.135           0.01          24  0.065753   \n",
       "6720           put    AMZN   15.200           0.60          38  0.104110   \n",
       "12147         call    NFLX  265.275           8.35         723  1.980822   \n",
       "\n",
       "              spot  moneyness  log_moneyness    bs_price  \n",
       "14090   165.190002   1.179929       0.165454   11.046335  \n",
       "4852    201.500000   0.959524      -0.041318    8.573163  \n",
       "2016    698.530029   0.812244      -0.207954  154.032561  \n",
       "5591    201.500000   1.185294       0.169991   51.068982  \n",
       "9218   1253.540039   1.027492       0.027121   91.147358  \n",
       "7107    208.470001   0.850898      -0.161463   35.396377  \n",
       "4781    201.500000   1.151429       0.141003    1.376708  \n",
       "12669   165.190002   0.825950      -0.191221    0.117213  \n",
       "6720    208.470001   0.947591      -0.053832   14.605194  \n",
       "12147  1253.540039   0.935478      -0.066698  309.176726  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fetch all the necessary data\n",
    "# Define FAANG tickers and names\n",
    "faang_tickers = {\n",
    "    \"META\": \"Meta (Facebook)\",\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"AMZN\": \"Amazon\",\n",
    "    \"NFLX\": \"Netflix\",\n",
    "    \"GOOGL\": \"Google\"}\n",
    "\n",
    "# Container for all data\n",
    "all_faang_options = []\n",
    "\n",
    "# Loop through each FAANG company\n",
    "for symbol, name in faang_tickers.items():\n",
    "    print(f\"Fetching options for {name} ({symbol})...\")\n",
    "    ticker = yf.Ticker(symbol)\n",
    "\n",
    "    expirations = ticker.options\n",
    "\n",
    "    for i, expiration in enumerate(expirations):\n",
    "        try:\n",
    "            option_chain = ticker.option_chain(expiration)\n",
    "\n",
    "            # Process calls and puts\n",
    "            for df, opt_type in [(option_chain.calls, 'call'), (option_chain.puts, 'put')]:\n",
    "                df = df.copy()\n",
    "                df['expiration'] = expiration\n",
    "                df['option_type'] = opt_type\n",
    "                df['ticker'] = symbol\n",
    "                all_faang_options.append(df)\n",
    "\n",
    "            print(f\"  - [{i+1}/{len(expirations)}] {expiration} OK\")\n",
    "            #time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  - Failed for {expiration}: {e}\")\n",
    "\n",
    "# Combine all FAANG options into a single DataFrame\n",
    "faang_df = pd.concat(all_faang_options, ignore_index=True)\n",
    "\n",
    "\n",
    "# drop empty values\n",
    "faang_df_clean = faang_df.dropna(subset=[\n",
    "    'lastPrice', 'impliedVolatility', 'strike', 'bid', 'ask', 'openInterest'\n",
    "])\n",
    "# clean unreasonable data\n",
    "faang_df_clean = faang_df_clean[\n",
    "    (faang_df_clean['lastPrice'] > 0) &\n",
    "    (faang_df_clean['impliedVolatility'] > 0) &\n",
    "    (faang_df_clean['bid'] >= 0) &\n",
    "    (faang_df_clean['ask'] >= 0) &\n",
    "    (faang_df_clean['openInterest'] > 0)\n",
    "]\n",
    "faang_df_clean['midPrice'] = (faang_df_clean['bid'] + faang_df_clean['ask']) / 2\n",
    "spread = faang_df_clean['ask'] - faang_df_clean['bid']\n",
    "faang_df_clean['ask_bid_spread']=spread\n",
    "faang_df_clean = faang_df_clean[spread / faang_df_clean['midPrice'] < 0.5]\n",
    "\n",
    "# Time to maturity in years\n",
    "faang_df_clean['expiration'] = pd.to_datetime(faang_df_clean['expiration'])\n",
    "faang_df_clean['days_to_exp'] = (faang_df_clean['expiration'] - datetime.today()).dt.days\n",
    "faang_df_clean = faang_df_clean[faang_df_clean['days_to_exp'] > 0]\n",
    "faang_df_clean['T'] = faang_df_clean['days_to_exp'] / 365\n",
    "\n",
    "# Fetch spot prices for each ticker (if needed)\n",
    "spot_prices = {ticker: yf.Ticker(ticker).history(period='1d')['Close'].iloc[-1]\n",
    "            for ticker in faang_df_clean['ticker'].unique()}\n",
    "\n",
    "faang_df_clean['spot'] = faang_df_clean['ticker'].map(spot_prices)\n",
    "\n",
    "# Moneyness\n",
    "faang_df_clean['moneyness'] = faang_df_clean['spot'] / faang_df_clean['strike']\n",
    "\n",
    "\n",
    "faang_df_clean = faang_df_clean[\n",
    "    (faang_df_clean['moneyness'] > 0.8) & (faang_df_clean['moneyness'] < 1.2) &\n",
    "    (faang_df_clean['T'] > 1/365)  # > 1 day to maturity\n",
    "]\n",
    "faang_df_clean['log_moneyness']=np.log(faang_df_clean['moneyness'] )\n",
    "\n",
    "\n",
    "#Black-Schole Price\n",
    "\n",
    "def black_scholes_price(S, K, T, r, sigma, option_type):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return np.nan  # skip invalid inputs\n",
    "\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    if option_type == 'call':\n",
    "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    elif option_type == 'put':\n",
    "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "    else:\n",
    "        return np.nan\n",
    "risk_free_rate = 0.0433\n",
    "faang_df_clean['bs_price'] = faang_df_clean.apply(\n",
    "    lambda row: black_scholes_price(\n",
    "        S=row['spot'],\n",
    "        K=row['strike'],\n",
    "        T=row['T'],\n",
    "        r=risk_free_rate,\n",
    "        sigma=row['impliedVolatility'],\n",
    "        option_type=row['option_type']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "faang_df_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2831213",
   "metadata": {},
   "source": [
    "ðŸŸ¦ Definitions:\n",
    "\n",
    "LastPrice is the most recent transaction price of an option, reflecting real market behavior.\n",
    "\n",
    "\n",
    "Black-Scholes Price is a theoretical value based on assumptions such as constant volatility, no arbitrage, and frictionless markets.\n",
    "\n",
    "\n",
    "ðŸŸ¨ Why use the Black-Scholes model?\n",
    "We use Black-Scholes as a baseline to estimate what the option should be worth under idealized conditions. Comparing this theoretical price to the observed lastPrice helps us identify deviations that may be due to market sentiment, liquidity constraints, or mispricing.\n",
    "\n",
    "\n",
    "ðŸŸ© What are we trying to do?\n",
    "Our objective is to develop a model that accurately predicts lastPrice. While Black-Scholes provides a clean theoretical benchmark, it doesnâ€™t fully capture the complexities of real markets. By modeling lastPrice, we aim to better understand and anticipate how options are actually priced in practiceâ€”accounting for behaviors, frictions, and nonlinearities beyond the scope of traditional theory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49fd20c",
   "metadata": {},
   "source": [
    "Here is where we keep all the candidate features for linear regressions, and the list of other models that we'd like to use to compare and determine the best model.\n",
    "\n",
    "#Constants here needs to be modified if more features and models needs to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57d67086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt to improve the black-scholes model by adding in the following variables\n",
    "candidate_list = ['bs_price', 'impliedVolatility', 'log_moneyness', 'ask_bid_spread']\n",
    "\n",
    "#code that generate all powerset of candidate list\n",
    "select = [[1], [0]]\n",
    "for i in range(len(candidate_list)-1):\n",
    "    select_new = []\n",
    "    for j in select:\n",
    "        j_0 = j.copy()\n",
    "        j_0.append(0)\n",
    "        j_1 = j.copy()\n",
    "        j_1.append(1)\n",
    "        select_new.append(j_0)\n",
    "        select_new.append(j_1)\n",
    "    select = select_new\n",
    "\n",
    "powerset_candidate_list = []\n",
    "for i in select:\n",
    "    subset = []\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == 1:\n",
    "            subset.append(candidate_list[j])\n",
    "    powerset_candidate_list.append(subset)\n",
    "\n",
    "## For each firm, try to evaluate the best model and features needed\n",
    "# Append bs_price to each candidate subset\n",
    "for subset in powerset_candidate_list:\n",
    "    if 'bs_price' not in subset:\n",
    "        subset.insert(0, 'bs_price')\n",
    "\n",
    "\n",
    "# Here is the list of \n",
    "num_splits = 5\n",
    "num_models = 7 + 1\n",
    "models_list = [\"BS-Model\", \"MLR\", \"KNN\", \"Ridge\", \"Lasso\", \"Bagging\", \"XGBoost\", \"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d7680975",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"MLR\": LinearRegression(),\n",
    "    \"KNN\": KNeighborsRegressor(10),\n",
    "    \"Ridge\": Ridge(alpha=1),\n",
    "    \"Lasso\": Lasso(alpha=1),\n",
    "    \"Bagging\": BaggingRegressor(\n",
    "        estimator=LinearRegression(),\n",
    "        n_estimators=100,\n",
    "        max_samples=1.0,\n",
    "        bootstrap=True,\n",
    "        random_state=216\n",
    "    ),\n",
    "    \"XGB\": XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5\n",
    "    ),\n",
    "    \"RF\": RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=4,\n",
    "        bootstrap=True,\n",
    "        random_state=216\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5be1a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmses(amses, company_name:str, train_set):\n",
    "    # Find the avg cv mse for each subset of features here\n",
    "    print(\"We are looking at\", company_name, \"based on\", train_set.shape[0])\n",
    "    print(\"The features that would produce the lowest mean cv mse are \\n\", \n",
    "        powerset_candidate_list[np.argmin(np.mean(amses, axis=0))],\n",
    "        \"\\n and using these features, there is an avg cv mse of\",\n",
    "        np.mean(amses, axis=0)[np.argmin(np.mean(amses, axis=0))], \n",
    "        \" across all the models.\\n\")\n",
    "\n",
    "    print(\"Among different models, the model with the best overall performance is\", \n",
    "        models_list[np.argmin(np.mean(amses, axis = 1))], \n",
    "        \"\\nIn comparison to the Black-Schole's model, it improves the performance by\", \n",
    "        float((np.mean(amses, axis=1)[0] - np.mean(amses, axis=1)[np.argmin(np.mean(amses, axis=1))])/np.mean(amses, axis=1)[0]) * 100, \"%.\\n\")\n",
    "\n",
    "    print()\n",
    "    # This code will print the improvement by each model\n",
    "    for model in range(len(models_list)):\n",
    "        print(\"The\", models_list[model], \"improved the performance by\", \n",
    "            float((np.mean(amses[0,:])- np.mean(amses[model,:]))/\n",
    "                                                np.mean(amses[0, :])) * 100, \"%.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d5e85",
   "metadata": {},
   "source": [
    "We will draw several graphs to compare the performances of each model. Here is where we keep track of the performances for each individual firm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e03cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_company_amses=pd.DataFrame({\n",
    "                        \"Meta\":[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        \"Apple\":[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        \"Amazon\":[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        \"Netflix\":[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        \"Google\":[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "}, index = models_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec43f2",
   "metadata": {},
   "source": [
    "Now we can look at each specific firm and determine the best models, and features that we need in order to best predict the option price.\n",
    "\n",
    "<h2> This is for Meta <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b23a5d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking at Meta based on 504\n",
      "The features that would produce the lowest mean cv mse are \n",
      " ['bs_price', 'impliedVolatility', 'log_moneyness', 'ask_bid_spread'] \n",
      " and using these features, there is an avg cv mse of 29.445602615416295  across all the models.\n",
      "\n",
      "Among different models, the model with the best overall performance is Bagging \n",
      "In comparison to the Black-Schole's model, it improves the performance by 86.54731877320538 %.\n",
      "\n",
      "\n",
      "The BS-Model improved the performance by 0.0 %.\n",
      "\n",
      "The MLR improved the performance by 86.53932816156737 %.\n",
      "\n",
      "The KNN improved the performance by 78.74082796179836 %.\n",
      "\n",
      "The Ridge improved the performance by 86.43972386773258 %.\n",
      "\n",
      "The Lasso improved the performance by 84.12660333012177 %.\n",
      "\n",
      "The Bagging improved the performance by 86.54731877320538 %.\n",
      "\n",
      "The XGBoost improved the performance by 84.09704437710302 %.\n",
      "\n",
      "The Random Forest improved the performance by 81.60072863868882 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us pick the data we want to focus on\n",
    "#calls =faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "calls =faang_df_clean[(faang_df_clean['ticker']=='META') & (faang_df_clean['option_type']=='call')]\n",
    "\n",
    "df_train, df_test= train_test_split(calls, test_size=0.2, shuffle=True,random_state=213)\n",
    "\n",
    "## This array will hold the average mse for each set of features and model\n",
    "amses_meta = np.zeros((num_models, len(powerset_candidate_list)))\n",
    "\n",
    "# set a feature counter\n",
    "k = 0\n",
    "\n",
    "for subset in powerset_candidate_list:\n",
    "    #state which features are we using to train the model\n",
    "    #print(\"We are now trying to train the model using \", subset)\n",
    "\n",
    "    kfold = KFold(n_splits = 5, random_state = 213, shuffle = True)\n",
    "\n",
    "    ## This array will hold the mse for each model and split\n",
    "    subset_mse = np.zeros((num_models, num_splits))\n",
    "\n",
    "    ## sets a split counter\n",
    "    i = 0\n",
    "\n",
    "    ## Implement time series data split\n",
    "    num_data = len(calls)\n",
    "    percent = 0.1\n",
    "    #kfold_time = TimeSeriesSplit(n_splits = 5, test_size= int(num_data*percent)) \n",
    "\n",
    "    ## loop through the kfold here\n",
    "    for train_index, test_index in kfold.split(df_train):\n",
    "        ## cv training set\n",
    "        calls_tt = df_train.iloc[train_index]\n",
    "        ## cv holdout set\n",
    "        calls_ho = df_train.iloc[test_index]\n",
    "\n",
    "        ## Fit and get ho mse for the baseline model (Black-Schole's model)\n",
    "        subset_mse[0, i] = mse(calls_ho[\"lastPrice\"], calls_ho[\"bs_price\"])\n",
    "\n",
    "        ##run through all models, predict, and attach the mse to rmses\n",
    "        for model_index, (model_name, model) in enumerate(models.items()):\n",
    "            model.fit(calls_tt[subset], calls_tt[\"lastPrice\"])\n",
    "            preds = model.predict(calls_ho[subset])\n",
    "            mse_val = mse(calls_ho[\"lastPrice\"], preds)\n",
    "\n",
    "            # Store or print results\n",
    "            subset_mse[model_index + 1, i] = mse_val\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    ## Append the avergae mse to amses\n",
    "    for j in range(num_models):\n",
    "        amses_meta[j, k] = np.mean(subset_mse[j,:])\n",
    "        \n",
    "    \n",
    "\n",
    "    k += 1\n",
    "\n",
    "evaluate_rmses(amses_meta, \"Meta\", calls_tt)\n",
    "    \n",
    "\n",
    "#Here is the code for us to record Meta's AMSES's data\n",
    "all_company_amses[\"Meta\"] = amses_meta[:,np.argmin(np.mean(amses_meta, axis=0))]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "288c27df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9ad260cd9a4300bf4677479ba29688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='Show Improved Price'), Output()), _dom_classes=('widgeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_with_toggle(show_scatter=True)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = np.argmin(np.mean(amses_meta, axis = 1))\n",
    "best_model = models_list[best_model_index]\n",
    "best_features = powerset_candidate_list[np.argmin(np.mean(amses_meta, axis=0))]\n",
    "\n",
    "model = list(models.items())[best_model_index-1][1]\n",
    "model.fit(df_train[best_features], df_train['lastPrice'])\n",
    "model_pred = model.predict(df_test[best_features])\n",
    "df_test[best_model] = model_pred\n",
    "\n",
    "# Toggle to show or hide the improved model prediction\n",
    "show_scatter = True  # Change to False to hide the scatter plot\n",
    "\n",
    "# Define the interactive function\n",
    "def plot_with_toggle(show_scatter=True):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # Plot y = x reference line\n",
    "    x = np.linspace(0, np.max(df_test[\"lastPrice\"]), 100)\n",
    "    plt.plot(x, x, color='blue', linestyle='--', label='y = x')\n",
    "\n",
    "    # Conditionally plot improved model prediction\n",
    "    if show_scatter:\n",
    "        plt.scatter(df_test[best_model], df_test['lastPrice'], label=\"Improved Price\")\n",
    "\n",
    "    # Always show the Black-Scholes prediction\n",
    "    plt.scatter(df_test[\"bs_price\"], df_test[\"lastPrice\"], label=\"BS Price Prediction\", color = \"orange\", alpha=0.5)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Adjusted Black-Scholes Price\")\n",
    "    plt.ylabel(\"Market Price\")\n",
    "    plt.title(\"Google Market Price vs Adjusted BS Prediction\\nCV MSE: {:.4f}\".format(\n",
    "        mse(df_test[\"lastPrice\"], model_pred)))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create and display the interactive widget\n",
    "widgets.interact(plot_with_toggle, show_scatter=widgets.Checkbox(value=True, description='Show Improved Price'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838817e4",
   "metadata": {},
   "source": [
    "<h2>This is for Apple<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c860707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking at Apple based on 208\n",
      "The features that would produce the lowest mean cv mse are \n",
      " ['bs_price', 'impliedVolatility', 'log_moneyness', 'ask_bid_spread'] \n",
      " and using these features, there is an avg cv mse of 2.5716004931445084  across all the models.\n",
      "\n",
      "Among different models, the model with the best overall performance is MLR \n",
      "In comparison to the Black-Schole's model, it improves the performance by 90.04048414999363 %.\n",
      "\n",
      "\n",
      "The BS-Model improved the performance by 0.0 %.\n",
      "\n",
      "The MLR improved the performance by 90.04048414999363 %.\n",
      "\n",
      "The KNN improved the performance by 77.30702817875662 %.\n",
      "\n",
      "The Ridge improved the performance by 89.17173248969287 %.\n",
      "\n",
      "The Lasso improved the performance by 83.39318126534275 %.\n",
      "\n",
      "The Bagging improved the performance by 89.86174661362244 %.\n",
      "\n",
      "The XGBoost improved the performance by 88.84335955124146 %.\n",
      "\n",
      "The Random Forest improved the performance by 80.63887896347406 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us pick the data we want to focus on\n",
    "#calls =faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "calls = faang_df_clean[(faang_df_clean['ticker']=='AAPL') & (faang_df_clean['option_type']=='call')]\n",
    "\n",
    "df_train, df_test= train_test_split(calls, test_size=0.2, shuffle=True,random_state=213)\n",
    "\n",
    "\n",
    "## This array will hold the average mse for each set of features and model\n",
    "amses_apple = np.zeros((num_models, len(powerset_candidate_list)))\n",
    "\n",
    "# set a feature counter\n",
    "k = 0\n",
    "\n",
    "\n",
    "for subset in powerset_candidate_list:\n",
    "    #state which features are we using to train the model\n",
    "    #print(\"We are now trying to train the model using \", subset)\n",
    "\n",
    "    kfold = KFold(n_splits = 5, random_state = 213, shuffle = True)\n",
    "\n",
    "    ## This array will hold the mse for each model and split\n",
    "    subset_mse = np.zeros((num_models, num_splits))\n",
    "\n",
    "    ## sets a split counter\n",
    "    i = 0\n",
    "\n",
    "    ## Implement time series data split\n",
    "    num_data = len(calls)\n",
    "    percent = 0.1\n",
    "    #kfold_time = TimeSeriesSplit(n_splits = 5, test_size= int(num_data*percent)) \n",
    "\n",
    "    ## loop through the kfold here\n",
    "    for train_index, test_index in kfold.split(df_train):\n",
    "        ## cv training set\n",
    "        calls_tt = df_train.iloc[train_index]\n",
    "        ## cv holdout set\n",
    "        calls_ho = df_train.iloc[test_index]\n",
    "\n",
    "        ## Fit and get ho mse for the baseline model (Black-Schole's model)\n",
    "        subset_mse[0, i] = mse(calls_ho[\"lastPrice\"], calls_ho[\"bs_price\"])\n",
    "\n",
    "        for model_index, (model_name, model) in enumerate(models.items()):\n",
    "            model.fit(calls_tt[subset], calls_tt[\"lastPrice\"])\n",
    "            preds = model.predict(calls_ho[subset])\n",
    "            mse_val = mse(calls_ho[\"lastPrice\"], preds)\n",
    "\n",
    "            # Store or print results\n",
    "            subset_mse[model_index + 1, i] = mse_val\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    ## Append the avergae mse to amses\n",
    "    for j in range(num_models):\n",
    "        amses_apple[j, k] = np.mean(subset_mse[j,:])\n",
    "    \n",
    "\n",
    "    k += 1\n",
    "\n",
    "evaluate_rmses(amses_apple, \"Apple\", calls_tt)\n",
    "    \n",
    "#here is the code for us to record Apple's performance\n",
    "all_company_amses[\"Apple\"] = amses_apple[:,np.argmin(np.mean(amses_apple, axis=0))]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "39b97512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7428296330840d7a181011843596695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='Show Improved Price'), Output()), _dom_classes=('widgeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_with_toggle(show_scatter=True)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = np.argmin(np.mean(amses_apple, axis = 1))\n",
    "best_model = models_list[best_model_index]\n",
    "best_features = powerset_candidate_list[np.argmin(np.mean(amses_apple, axis=0))]\n",
    "\n",
    "model = list(models.items())[best_model_index-1][1]\n",
    "model.fit(df_train[best_features], df_train['lastPrice'])\n",
    "model_pred = model.predict(df_test[best_features])\n",
    "df_test[best_model] = model_pred\n",
    "\n",
    "# Toggle to show or hide the improved model prediction\n",
    "show_scatter = True  # Change to False to hide the scatter plot\n",
    "\n",
    "# Define the interactive function\n",
    "def plot_with_toggle(show_scatter=True):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # Plot y = x reference line\n",
    "    x = np.linspace(0, np.max(df_test[\"lastPrice\"]), 100)\n",
    "    plt.plot(x, x, color='blue', linestyle='--', label='y = x')\n",
    "\n",
    "    # Conditionally plot improved model prediction\n",
    "    if show_scatter:\n",
    "        plt.scatter(df_test[best_model], df_test['lastPrice'], label=\"Improved Price\")\n",
    "\n",
    "    # Always show the Black-Scholes prediction\n",
    "    plt.scatter(df_test[\"bs_price\"], df_test[\"lastPrice\"], label=\"BS Price Prediction\", color = \"orange\", alpha=0.5)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Adjusted Black-Scholes Price\")\n",
    "    plt.ylabel(\"Market Price\")\n",
    "    plt.title(\"Google Market Price vs Adjusted BS Prediction\\nCV MSE: {:.4f}\".format(\n",
    "        mse(df_test[\"lastPrice\"], model_pred)))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create and display the interactive widget\n",
    "widgets.interact(plot_with_toggle, show_scatter=widgets.Checkbox(value=True, description='Show Improved Price'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21819306",
   "metadata": {},
   "source": [
    "<h2>This is for Amazon <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9a64ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking at Amazon based on 223\n",
      "The features that would produce the lowest mean cv mse are \n",
      " ['bs_price', 'impliedVolatility', 'log_moneyness'] \n",
      " and using these features, there is an avg cv mse of 2.9895000328710095  across all the models.\n",
      "\n",
      "Among different models, the model with the best overall performance is MLR \n",
      "In comparison to the Black-Schole's model, it improves the performance by 86.0319389930616 %.\n",
      "\n",
      "\n",
      "The BS-Model improved the performance by 0.0 %.\n",
      "\n",
      "The MLR improved the performance by 86.0319389930616 %.\n",
      "\n",
      "The KNN improved the performance by 63.742990990067184 %.\n",
      "\n",
      "The Ridge improved the performance by 84.69073476475859 %.\n",
      "\n",
      "The Lasso improved the performance by 76.18340461889366 %.\n",
      "\n",
      "The Bagging improved the performance by 85.94763091934375 %.\n",
      "\n",
      "The XGBoost improved the performance by 80.998304407361 %.\n",
      "\n",
      "The Random Forest improved the performance by 68.19329315593745 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us pick the data we want to focus on\n",
    "#calls =faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "calls = faang_df_clean[(faang_df_clean['ticker']=='AMZN') & (faang_df_clean['option_type']=='call')]\n",
    "\n",
    "df_train, df_test= train_test_split(calls, test_size=0.2, shuffle=True,random_state=213)\n",
    "\n",
    "\n",
    "## This array will hold the average mse for each set of features and model\n",
    "amses_amazon = np.zeros((num_models, len(powerset_candidate_list)))\n",
    "\n",
    "# set a feature counter\n",
    "k = 0\n",
    "\n",
    "for subset in powerset_candidate_list:\n",
    "    #state which features are we using to train the model\n",
    "    #print(\"We are now trying to train the model using \", subset)\n",
    "\n",
    "    kfold = KFold(n_splits = 5, random_state = 213, shuffle = True)\n",
    "\n",
    "    ## This array will hold the mse for each model and split\n",
    "    subset_mse = np.zeros((num_models, num_splits))\n",
    "\n",
    "    ## sets a split counter\n",
    "    i = 0\n",
    "\n",
    "    ## Implement time series data split\n",
    "    num_data = len(calls)\n",
    "    percent = 0.1\n",
    "    #kfold_time = TimeSeriesSplit(n_splits = 5, test_size= int(num_data*percent)) \n",
    "\n",
    "    ## loop through the kfold here\n",
    "    for train_index, test_index in kfold.split(df_train):\n",
    "        ## cv training set\n",
    "        calls_tt = df_train.iloc[train_index]\n",
    "        ## cv holdout set\n",
    "        calls_ho = df_train.iloc[test_index]\n",
    "\n",
    "        ## Fit and get ho mse for the baseline model (Black-Schole's model)\n",
    "        subset_mse[0, i] = mse(calls_ho[\"lastPrice\"], calls_ho[\"bs_price\"])\n",
    "\n",
    "        for model_index, (model_name, model) in enumerate(models.items()):\n",
    "            model.fit(calls_tt[subset], calls_tt[\"lastPrice\"])\n",
    "            preds = model.predict(calls_ho[subset])\n",
    "            mse_val = mse(calls_ho[\"lastPrice\"], preds)\n",
    "\n",
    "            # Store or print results\n",
    "            subset_mse[model_index + 1, i] = mse_val\n",
    "        i += 1\n",
    "\n",
    "    ## Append the avergae mse to amses\n",
    "    for j in range(num_models):\n",
    "        amses_amazon[j, k] = np.mean(subset_mse[j,:])\n",
    "    \n",
    "\n",
    "    k += 1\n",
    "\n",
    "evaluate_rmses(amses_amazon, \"Amazon\", calls_tt)\n",
    "\n",
    "#here is the code for us to record Amazon's performance\n",
    "all_company_amses[\"Amazon\"] = amses_amazon[:,np.argmin(np.mean(amses_amazon, axis=0))]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fc8f4a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adf671565e040d389a1eabecdd1e3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='Show Improved Price'), Output()), _dom_classes=('widgeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_with_toggle(show_scatter=True)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = np.argmin(np.mean(amses_amazon, axis = 1))\n",
    "best_model = models_list[best_model_index]\n",
    "best_features = powerset_candidate_list[np.argmin(np.mean(amses_amazon, axis=0))]\n",
    "\n",
    "model = list(models.items())[best_model_index-1][1]\n",
    "model.fit(df_train[best_features], df_train['lastPrice'])\n",
    "model_pred = model.predict(df_test[best_features])\n",
    "df_test[best_model] = model_pred\n",
    "\n",
    "# Toggle to show or hide the improved model prediction\n",
    "show_scatter = True  # Change to False to hide the scatter plot\n",
    "\n",
    "# Define the interactive function\n",
    "def plot_with_toggle(show_scatter=True):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # Plot y = x reference line\n",
    "    x = np.linspace(0, np.max(df_test[\"lastPrice\"]), 100)\n",
    "    plt.plot(x, x, color='blue', linestyle='--', label='y = x')\n",
    "\n",
    "    # Conditionally plot improved model prediction\n",
    "    if show_scatter:\n",
    "        plt.scatter(df_test[best_model], df_test['lastPrice'], label=\"Improved Price\")\n",
    "\n",
    "    # Always show the Black-Scholes prediction\n",
    "    plt.scatter(df_test[\"bs_price\"], df_test[\"lastPrice\"], label=\"BS Price Prediction\", color = \"orange\", alpha=0.5)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Adjusted Black-Scholes Price\")\n",
    "    plt.ylabel(\"Market Price\")\n",
    "    plt.title(\"Google Market Price vs Adjusted BS Prediction\\nCV MSE: {:.4f}\".format(\n",
    "        mse(df_test[\"lastPrice\"], model_pred)))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create and display the interactive widget\n",
    "widgets.interact(plot_with_toggle, show_scatter=widgets.Checkbox(value=True, description='Show Improved Price'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ed386",
   "metadata": {},
   "source": [
    "<h2> This is for Netflix <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4dfabfec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_index, (model_name, model) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models.items()):\n\u001b[32m     42\u001b[39m     model.fit(calls_tt[subset], calls_tt[\u001b[33m\"\u001b[39m\u001b[33mlastPrice\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     preds = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalls_ho\u001b[49m\u001b[43m[\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     mse_val = mse(calls_ho[\u001b[33m\"\u001b[39m\u001b[33mlastPrice\u001b[39m\u001b[33m\"\u001b[39m], preds)\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Store or print results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:1079\u001b[39m, in \u001b[36mForestRegressor.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1077\u001b[39m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[32m   1078\u001b[39m lock = threading.Lock()\n\u001b[32m-> \u001b[39m\u001b[32m1079\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msharedmem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimators_\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m y_hat /= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_)\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:731\u001b[39m, in \u001b[36m_accumulate_prediction\u001b[39m\u001b[34m(predict, X, out, lock)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[32m    725\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    726\u001b[39m \u001b[33;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[32m    727\u001b[39m \n\u001b[32m    728\u001b[39m \u001b[33;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[33;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[32m    730\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     prediction = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m    733\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/tree/_classes.py:535\u001b[39m, in \u001b[36mBaseDecisionTree.predict\u001b[39m\u001b[34m(self, X, check_input)\u001b[39m\n\u001b[32m    532\u001b[39m n_samples = X.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# Classification\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m:\n\u001b[32m    537\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_.take(np.argmax(proba, axis=\u001b[32m1\u001b[39m), axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/base.py:1237\u001b[39m, in \u001b[36mis_classifier\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m   1230\u001b[39m     warnings.warn(\n\u001b[32m   1231\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect.stack()[\u001b[32m0\u001b[39m][\u001b[32m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1232\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1233\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1234\u001b[39m     )\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33m_estimator_type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m.estimator_type == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/utils/_tags.py:393\u001b[39m, in \u001b[36mget_tags\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tags\u001b[39m(estimator) -> Tags:\n\u001b[32m    368\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get estimator tags.\u001b[39;00m\n\u001b[32m    369\u001b[39m \n\u001b[32m    370\u001b[39m \u001b[33;03m    :class:`~sklearn.BaseEstimator` provides the estimator tags machinery.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m \u001b[33;03m        The estimator tags.\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     tag_provider = \u001b[43m_find_tags_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tag_provider == \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    396\u001b[39m         \u001b[38;5;66;03m# TODO(1.7): turn the warning into an error\u001b[39;00m\n\u001b[32m    397\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/utils/_tags.py:340\u001b[39m, in \u001b[36m_find_tags_provider\u001b[39m\u001b[34m(estimator, warn)\u001b[39m\n\u001b[32m    338\u001b[39m tag_provider = \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m tags_mro:\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     has_get_or_more_tags = \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags_mro\u001b[49m\u001b[43m[\u001b[49m\u001b[43mklass\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_get_tags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_more_tags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m     has_sklearn_tags = \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tags_mro[klass]\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tags_mro[klass] \u001b[38;5;129;01mand\u001b[39;00m tag_provider == \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# is it empty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/erdos_summer_2025/lib/python3.12/site-packages/sklearn/utils/_tags.py:341\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    338\u001b[39m tag_provider = \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m tags_mro:\n\u001b[32m    340\u001b[39m     has_get_or_more_tags = \u001b[38;5;28many\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m         provider \u001b[38;5;129;01min\u001b[39;00m tags_mro[klass] \u001b[38;5;28;01mfor\u001b[39;00m provider \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m_get_tags\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_more_tags\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    342\u001b[39m     )\n\u001b[32m    343\u001b[39m     has_sklearn_tags = \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tags_mro[klass]\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tags_mro[klass] \u001b[38;5;129;01mand\u001b[39;00m tag_provider == \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# is it empty\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# let us pick the data we want to focus on\n",
    "#calls =faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "calls = faang_df_clean[(faang_df_clean['ticker']=='NFLX') & (faang_df_clean['option_type']=='call')]\n",
    "\n",
    "df_train, df_test= train_test_split(calls, test_size=0.2, shuffle=True,random_state=213)\n",
    "\n",
    "## This array will hold the average mse for each set of features and model\n",
    "amses_netflix = np.zeros((num_models, len(powerset_candidate_list)))\n",
    "\n",
    "# set a feature counter\n",
    "k = 0\n",
    "\n",
    "for subset in powerset_candidate_list:\n",
    "    #state which features are we using to train the model\n",
    "    #print(\"We are now trying to train the model using \", subset)\n",
    "\n",
    "    kfold = KFold(n_splits = 5, random_state = 213, shuffle = True)\n",
    "\n",
    "    ## This array will hold the mse for each model and split\n",
    "    subset_mse = np.zeros((num_models, num_splits))\n",
    "\n",
    "    ## sets a split counter\n",
    "    i = 0\n",
    "\n",
    "    ## Implement time series data split\n",
    "    num_data = len(calls)\n",
    "    percent = 0.1\n",
    "    #kfold_time = TimeSeriesSplit(n_splits = 5, test_size= int(num_data*percent)) \n",
    "\n",
    "    ## loop through the kfold here\n",
    "    for train_index, test_index in kfold.split(df_train):\n",
    "        ## cv training set\n",
    "        calls_tt = df_train.iloc[train_index]\n",
    "        ## cv holdout set\n",
    "        calls_ho = df_train.iloc[test_index]\n",
    "\n",
    "        ## Fit and get ho mse for the baseline model (Black-Schole's model)\n",
    "        subset_mse[0, i] = mse(calls_ho[\"lastPrice\"], calls_ho[\"bs_price\"])\n",
    "\n",
    "        for model_index, (model_name, model) in enumerate(models.items()):\n",
    "            model.fit(calls_tt[subset], calls_tt[\"lastPrice\"])\n",
    "            preds = model.predict(calls_ho[subset])\n",
    "            mse_val = mse(calls_ho[\"lastPrice\"], preds)\n",
    "\n",
    "            # Store or print results\n",
    "            subset_mse[model_index + 1, i] = mse_val\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    ## Append the avergae mse to amses\n",
    "    for j in range(num_models):\n",
    "        amses_netflix[j, k] = np.mean(subset_mse[j,:])\n",
    "    \n",
    "\n",
    "    k += 1\n",
    "\n",
    "evaluate_rmses(amses_netflix, \"Netflix\", calls_tt)\n",
    "    \n",
    "#here is the code for us to record Netflix's performance\n",
    "all_company_amses[\"Netflix\"] = amses_netflix[:,np.argmin(np.mean(amses_netflix, axis=0))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa7cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd754dce06b4095a1c7f33b35fca702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='Show Improved Price'), Output()), _dom_classes=('widgeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_with_toggle(show_scatter=True)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = np.argmin(np.mean(amses_netflix, axis = 1))\n",
    "best_model = models_list[best_model_index]\n",
    "best_features = powerset_candidate_list[np.argmin(np.mean(amses_netflix, axis=0))]\n",
    "\n",
    "model = list(models.items())[best_model_index-1][1]\n",
    "model.fit(df_train[best_features], df_train['lastPrice'])\n",
    "model_pred = model.predict(df_test[best_features])\n",
    "df_test[best_model] = model_pred\n",
    "\n",
    "# Toggle to show or hide the improved model prediction\n",
    "show_scatter = True  # Change to False to hide the scatter plot\n",
    "\n",
    "# Define the interactive function\n",
    "def plot_with_toggle(show_scatter=True):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # Plot y = x reference line\n",
    "    x = np.linspace(0, np.max(df_test[\"lastPrice\"]), 100)\n",
    "    plt.plot(x, x, color='blue', linestyle='--', label='y = x')\n",
    "\n",
    "    # Always show the Black-Scholes prediction\n",
    "    plt.scatter(df_test[\"bs_price\"], df_test[\"lastPrice\"], label=\"BS Price Prediction\", color = \"orange\", alpha=0.5)\n",
    "\n",
    "    # Conditionally plot improved model prediction\n",
    "    if show_scatter:\n",
    "        plt.scatter(df_test[best_model], df_test['lastPrice'], label=\"Improved Price\")\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Adjusted Black-Scholes Price\")\n",
    "    plt.ylabel(\"Market Price\")\n",
    "    plt.title(\"Google Market Price vs Adjusted BS Prediction\\nCV MSE: {:.4f}\".format(\n",
    "        mse(df_test[\"lastPrice\"], model_pred)))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create and display the interactive widget\n",
    "widgets.interact(plot_with_toggle, show_scatter=widgets.Checkbox(value=True, description='Show Improved Price'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571c4df",
   "metadata": {},
   "source": [
    "<h2>This is for Google <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a38a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking at Google based on 176\n",
      "The features that would produce the lowest mean cv mse are \n",
      " ['bs_price', 'impliedVolatility', 'log_moneyness', 'ask_bid_spread'] \n",
      " and using these features, there is an avg cv mse of 3.862891711338283  across all the models.\n",
      "\n",
      "Among different models, the model with the best overall performance is MLR \n",
      "In comparison to the Black-Schole's model, it improves the performance by 70.45871320440105 %.\n",
      "\n",
      "\n",
      "The BS-Model improved the performance by 0.0 %.\n",
      "\n",
      "The MLR improved the performance by 70.45871320440105 %.\n",
      "\n",
      "The KNN improved the performance by 49.05897591482988 %.\n",
      "\n",
      "The Ridge improved the performance by 69.36167637438467 %.\n",
      "\n",
      "The Lasso improved the performance by 59.462984523099095 %.\n",
      "\n",
      "The Bagging improved the performance by 70.3150676564011 %.\n",
      "\n",
      "The XGBoost improved the performance by 60.975229737735184 %.\n",
      "\n",
      "The Random Forest improved the performance by 48.51824486742714 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let us pick the data we want to focus on\n",
    "#calls =faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "calls = faang_df_clean[(faang_df_clean['ticker']=='GOOGL') & (faang_df_clean['option_type']=='call')]\n",
    "\n",
    "df_train, df_test= train_test_split(calls, test_size=0.2, shuffle=True,random_state=213)\n",
    "\n",
    "## This array will hold the average mse for each set of features and model\n",
    "amses_google = np.zeros((num_models, len(powerset_candidate_list)))\n",
    "\n",
    "# set a feature counter\n",
    "k = 0\n",
    "\n",
    "for subset in powerset_candidate_list:\n",
    "\n",
    "    #creating the k-fold splitting\n",
    "    kfold = KFold(n_splits = 5, random_state = 213, shuffle = True)\n",
    "\n",
    "    ## This array will hold the mse for each model and split\n",
    "    subset_mse = np.zeros((num_models, num_splits))\n",
    "\n",
    "    ## sets a split counter\n",
    "    i = 0\n",
    "\n",
    "    ## Implement time series data split\n",
    "    num_data = len(calls)\n",
    "    percent = 0.1\n",
    "    #kfold_time = TimeSeriesSplit(n_splits = 5, test_size= int(num_data*percent)) \n",
    "\n",
    "    ## loop through the kfold here\n",
    "    for train_index, test_index in kfold.split(df_train):\n",
    "        ## cv training set\n",
    "        calls_tt = df_train.iloc[train_index]\n",
    "        ## cv holdout set\n",
    "        calls_ho = df_train.iloc[test_index]\n",
    "\n",
    "        ## Fit and get ho mse for the baseline model (Black-Schole's model)\n",
    "        subset_mse[0, i] = mse(calls_ho[\"lastPrice\"], calls_ho[\"bs_price\"])\n",
    "\n",
    "        for model_index, (model_name, model) in enumerate(models.items()):\n",
    "            model.fit(calls_tt[subset], calls_tt[\"lastPrice\"])\n",
    "            preds = model.predict(calls_ho[subset])\n",
    "            mse_val = mse(calls_ho[\"lastPrice\"], preds)\n",
    "\n",
    "            # Store or print results\n",
    "            subset_mse[model_index + 1, i] = mse_val\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    ## Append the avergae mse to amses\n",
    "    for j in range(num_models):\n",
    "        amses_google[j, k] = np.mean(subset_mse[j,:])\n",
    "    \n",
    "\n",
    "    k += 1\n",
    "\n",
    "evaluate_rmses(amses_google, \"Google\", calls_tt)\n",
    "    \n",
    "#here is the code for us to record Google's performance\n",
    "all_company_amses[\"Google\"] = amses_google[:,np.argmin(np.mean(amses_google, axis=0))] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f654c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49550855e+00  2.64475889e+01  1.00150784e+00  4.14300286e+01\n",
      " -6.08074882e-01  3.46883777e+01  4.19407599e+01  3.03537428e+01\n",
      "  9.62041359e-01  2.71760001e+01  2.27260869e+01  1.63668926e+00\n",
      "  2.85710174e+01  3.78811388e+01  4.33919313e+01  3.47602881e+01\n",
      "  4.19716015e-01  9.86511046e+00  1.16498422e+01 -5.24920592e-02\n",
      "  2.10466861e+01  2.58695132e+01  1.25183376e+01  2.52700381e+01\n",
      "  1.26562441e+01  1.93511495e+01  2.71009249e+01  4.29439284e+00\n",
      "  2.09520113e+00  2.47623565e+01  1.03716286e+00  1.44414684e-01\n",
      "  3.21878790e+00  9.18629918e+00  1.16370194e+01  1.95316909e-01\n",
      "  1.96975594e+01  3.46139594e+01 -1.17900266e-02  3.92457740e-01\n",
      "  6.58559609e+00  6.09595841e+00  2.91577367e+01  1.41670594e+01\n",
      "  5.96053657e+00  4.87431256e+01  3.25700141e+01 -1.15887333e-01\n",
      "  5.55842154e-01  3.92960569e+01  2.59153359e+01  1.55168047e+00\n",
      "  9.56808963e+00 -3.84914796e-01  3.99446810e+00]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7382dfe84de342b3808ffc6d0f6453db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='Show Improved Price'), Output()), _dom_classes=('widgeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_with_toggle(show_scatter=True)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = np.argmin(np.mean(amses_google, axis = 1))\n",
    "best_model = models_list[best_model_index]\n",
    "best_features = powerset_candidate_list[np.argmin(np.mean(amses_google, axis=0))]\n",
    "\n",
    "model = list(models.items())[best_model_index-1][1]\n",
    "model.fit(df_train[best_features], df_train['lastPrice'])\n",
    "model_pred = model.predict(df_test[best_features])\n",
    "print(model_pred)\n",
    "df_test[best_model] = model_pred\n",
    "\n",
    "# Toggle to show or hide the improved model prediction\n",
    "show_scatter = True  # Change to False to hide the scatter plot\n",
    "\n",
    "# Define the interactive function\n",
    "def plot_with_toggle(show_scatter=True):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # Plot y = x reference line\n",
    "    x = np.linspace(0, np.max(df_test[\"lastPrice\"]), 100)\n",
    "    plt.plot(x, x, color='blue', linestyle='--', label='y = x')\n",
    "\n",
    "    # Conditionally plot improved model prediction\n",
    "    if show_scatter:\n",
    "        plt.scatter(df_test[best_model], df_test['lastPrice'], label=\"Improved Price\")\n",
    "\n",
    "    # Always show the Black-Scholes prediction\n",
    "    plt.scatter(df_test[\"bs_price\"], df_test[\"lastPrice\"], label=\"BS Price Prediction\", color = \"orange\", alpha=0.5)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Adjusted Black-Scholes Price\")\n",
    "    plt.ylabel(\"Market Price\")\n",
    "    plt.title(\"Google Market Price vs Adjusted BS Prediction\\nCV MSE: {:.4f}\".format(\n",
    "        mse(df_test[\"lastPrice\"], model_pred)))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create and display the interactive widget\n",
    "widgets.interact(plot_with_toggle, show_scatter=widgets.Checkbox(value=True, description='Show Improved Price'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f45d75",
   "metadata": {},
   "source": [
    "The plot I generated shows, for each company, the mean squared error (MSE) between the predicted option prices from each model and the observed lastPrice. Note that the MSEs in the plot are not the actual values â€” I applied a scaling factor to make the Black-Scholes model's price the same across all companies and scaled the predictions from all other models by the same factor. This allows for a more intuitive visual comparison of the relative improvement each model achieves, as reflected by the reduction in bar height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65501df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardized all bs model MSE\n",
    "for i in range(all_company_amses.shape[1]-1):\n",
    "    coef = float(all_company_amses.iloc[0, 0]/all_company_amses.iloc[0, i+1])\n",
    "    for j in range(all_company_amses.shape[0]):\n",
    "        all_company_amses.iloc[j, i+1] *= coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the explanation above to correctly interpret the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the bar chart for comparing model efficiency\n",
    "all_company_amses.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "print(\"Read the explanation above to correctly interpret the graph.\")\n",
    "plt.title('Scaled Model Performance for Each Company')\n",
    "plt.ylabel('Average MSE')  # or any performance metric you're using\n",
    "plt.xlabel('Models')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Company')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e7c6b",
   "metadata": {},
   "source": [
    "Improvement for all companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e56a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are looking at all companies based on 1552 data.\n",
      "The features that would produce the lowest mean cv mse are \n",
      " ['bs_price', 'impliedVolatility', 'log_moneyness', 'ask_bid_spread'] \n",
      " and using these features, there is an avg cv mse of 57.844901563456496  across all the models.\n",
      "\n",
      "Among different models, the model with the best overall performance is Random Forest \n",
      "In comparison to the Black-Schole's model, it improves the performance by 79.90756104372329 %.\n",
      "\n",
      "\n",
      "The BS-Model improved the performance by 0.0 %.\n",
      "\n",
      "The MLR improved the performance by 77.16122368058177 %.\n",
      "\n",
      "The KNN improved the performance by 74.97779348567548 %.\n",
      "\n",
      "The Ridge improved the performance by 77.14221525274046 %.\n",
      "\n",
      "The Lasso improved the performance by 73.60094461968212 %.\n",
      "\n",
      "The Bagging improved the performance by 77.16567516470492 %.\n",
      "\n",
      "The XGBoost improved the performance by 77.00356444898142 %.\n",
      "\n",
      "The Random Forest improved the performance by 79.90756104372329 %.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us pick the data we want to focus on\n",
    "#calls =faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "calls = faang_df_clean[(faang_df_clean['option_type']=='call')]\n",
    "\n",
    "df_train, df_test= train_test_split(calls, test_size=0.2, shuffle=True,random_state=213)\n",
    "\n",
    "## This array will hold the average mse for each set of features and model\n",
    "amses = np.zeros((num_models, len(powerset_candidate_list)))\n",
    "\n",
    "# set a feature counter\n",
    "k = 0\n",
    "\n",
    "for subset in powerset_candidate_list:\n",
    "    #state which features are we using to train the model\n",
    "    #print(\"We are now trying to train the model using \", subset)\n",
    "\n",
    "    kfold = KFold(n_splits = 5, shuffle = True, random_state = 213)\n",
    "\n",
    "    ## This array will hold the mse for each model and split\n",
    "    rmses = np.zeros((num_models, num_splits))\n",
    "\n",
    "    ## sets a split counter\n",
    "    i = 0\n",
    "\n",
    "    ## Implement time series data split\n",
    "    num_data = len(calls)\n",
    "    percent = 0.1\n",
    "    #kfold_time = TimeSeriesSplit(n_splits = 5, test_size= int(num_data*percent)) \n",
    "\n",
    "    ## loop through the kfold here\n",
    "    for train_index, test_index in kfold.split(df_train):\n",
    "        ## cv training set\n",
    "        calls_tt = df_train.iloc[train_index]\n",
    "        ## cv holdout set\n",
    "        calls_ho = df_train.iloc[test_index]\n",
    "\n",
    "        ## Fit and get ho mse for the baseline model (Black-Schole's model)\n",
    "        rmses[0, i] = mse(calls_ho[\"lastPrice\"], calls_ho[\"bs_price\"])\n",
    "\n",
    "        for model_index, (model_name, model) in enumerate(models.items()):\n",
    "            model.fit(calls_tt[subset], calls_tt[\"lastPrice\"])\n",
    "            preds = model.predict(calls_ho[subset])\n",
    "            mse_val = mse(calls_ho[\"lastPrice\"], preds)\n",
    "\n",
    "            # Store or print results\n",
    "            rmses[model_index + 1, i] = mse_val\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    ## Append the avergae mse to amses\n",
    "    for j in range(num_models):\n",
    "        amses[j, k] = np.mean(rmses[j,:])\n",
    "    k += 1\n",
    "\n",
    "# Find the avg cv mse for each subset of features here\n",
    "print(\"We are looking at all companies based on\", calls_tt.shape[0], \"data.\")\n",
    "print(\"The features that would produce the lowest mean cv mse are \\n\", \n",
    "    powerset_candidate_list[np.argmin(np.mean(amses, axis=0))],\n",
    "    \"\\n and using these features, there is an avg cv mse of\",\n",
    "    np.mean(amses, axis=0)[np.argmin(np.mean(amses, axis=0))], \n",
    "    \" across all the models.\\n\")\n",
    "\n",
    "print(\"Among different models, the model with the best overall performance is\", \n",
    "    models_list[np.argmin(np.mean(amses, axis = 1))], \n",
    "    \"\\nIn comparison to the Black-Schole's model, it improves the performance by\", \n",
    "    float((np.mean(amses, axis=1)[0] - np.mean(amses, axis=1)[np.argmin(np.mean(amses, axis=1))])/np.mean(amses, axis=1)[0]) * 100, \"%.\\n\")\n",
    "\n",
    "print()\n",
    "# This code will print the improvement by each model\n",
    "for model in range(len(models_list)):\n",
    "    print(\"The\", models_list[model], \"improved the performance by\", \n",
    "        float((np.mean(amses[0,:])- np.mean(amses[model,:]))/\n",
    "                                            np.mean(amses[0, :])) * 100, \"%.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
